{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_families(data_path,data_delimiter=' ',ID_header_1='ID1',ID_header_2='ID2'):\n",
    "    \n",
    "    # Indicate current task\n",
    "    print('\\nGrouping IDs in the same family\\n',end='')\n",
    "    \n",
    "    # Read input\n",
    "    data = pd.read_csv(data_path,sep=data_delimiter)[[ID_header_1,ID_header_2]]\n",
    "    \n",
    "    # For progress calculation\n",
    "    tic = time.time()\n",
    "    total_length = len(data)\n",
    "    \n",
    "    # Repeat grouping until every pair has been exhausted\n",
    "    family_list = []\n",
    "    while len(data) > 0:\n",
    "        incomplete = True\n",
    "        family = [list(data[ID_header_1])[0],list(data[ID_header_2])[0]]\n",
    "        data = data.iloc[1:,:]\n",
    "        \n",
    "        # Repeatedly search for new members of family\n",
    "        while incomplete:\n",
    "            \n",
    "            # Find all new entries to add to current family\n",
    "            new_ID = data.isin(family)\n",
    "            \n",
    "            # Detecting if no new entries will be added to current family\n",
    "            if sum(new_ID[ID_header_1]) + sum(new_ID[ID_header_2]) == 0:\n",
    "                #print(family)\n",
    "                family_list.append(family)\n",
    "                incomplete = False\n",
    "                continue\n",
    "                \n",
    "            # Remove all irrelevant rows\n",
    "            new_ID = new_ID[np.logical_or(new_ID[ID_header_1] == True, new_ID[ID_header_2] == True)]\n",
    "            \n",
    "            # Debug\n",
    "            #display(new_ID)\n",
    "            #display(data.loc[new_ID.index,:])\n",
    "            #display(fulldata.loc[new_ID.index])\n",
    "            \n",
    "            # Update list of IDs for current working family\n",
    "            for (index,row) in new_ID.iterrows():\n",
    "                for item in data.loc[index,:]:\n",
    "                    if item not in family:\n",
    "                        family.append(item)\n",
    "                data.drop(index, inplace=True)\n",
    "        \n",
    "        # Calculate and display progress\n",
    "        toc = time.time()\n",
    "        if toc-tic > 1:\n",
    "            print(f'\\rProgress: {total_length-len(data)}/{total_length} Family Count: {len(family_list)}',end='')\n",
    "            tic = time.time()\n",
    "    \n",
    "    # Indicate completed task\n",
    "    print(f'\\rProgress: {total_length-len(data)}/{total_length} Family Count: {len(family_list)}',end='')\n",
    "    print('\\nDone',end='')\n",
    "    return pd.DataFrame({'family':family_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_relations(data_path,data_delimiter,ID_header_1,ID_header_2,relation_header):\n",
    "    \n",
    "    '''\n",
    "    Relationship Key:\n",
    "    S = Self\n",
    "    D = Duplicate or Monozygotic Twin\n",
    "    P = Parent\n",
    "    F = First Sibling (Relation by Parents)\n",
    "    2 = 2nd Sibling (Relation by Single Parent ~25% shared genetics)\n",
    "    3 = 3rd Sibling (Relation by ~12.5% shared genetics)\n",
    "    '''\n",
    "\n",
    "    # Indicate current task\n",
    "    print('\\nObtaining relationships in family\\n',end='')\n",
    "    \n",
    "    # Read input\n",
    "    data = pd.read_csv(data_path,sep=data_delimiter)\n",
    "    \n",
    "    # For progress calculation\n",
    "    tic = time.time()\n",
    "    total_length = len(family_data)\n",
    "    \n",
    "    # Obtain relationship matrix and relation for each family\n",
    "    relations = []\n",
    "    for (index,row) in family_data.iterrows():\n",
    "        \n",
    "        # Generate empty matrix with correct dimensions\n",
    "        dim = len(row[0])\n",
    "        matrix = np.full((dim,dim),' ',dtype='U')\n",
    "        \n",
    "        # Fill diagonal\n",
    "        for i in range(0,dim):\n",
    "            matrix[i,i] = 'S'\n",
    "        \n",
    "        # Find all relevant relation information\n",
    "        target = data.isin(row[0])\n",
    "        target = target[np.logical_and(target[ID_header_1] == True, target[ID_header_2] == True)].index\n",
    "        relation_data = data.loc[target,:]\n",
    "        \n",
    "        # Update matrix with proper values\n",
    "        for (i,info) in relation_data.iterrows():\n",
    "            ID1_index = row[0].index(info[ID_header_1])\n",
    "            ID2_index = row[0].index(info[ID_header_2])\n",
    "            relation = info[relation_header][0]\n",
    "            matrix[ID1_index,ID2_index] = relation\n",
    "            matrix[ID2_index,ID1_index] = relation\n",
    "        relations.append(matrix)\n",
    "        \n",
    "        # Calculate and display progress\n",
    "        toc = time.time()\n",
    "        if toc-tic > 1:\n",
    "            print(f'\\rProgress: {index+1}/{total_length}',end='')\n",
    "            tic = time.time()\n",
    "    \n",
    "    # Indicate completed task\n",
    "    print(f'\\rProgress: {index+1}/{total_length}',end='')\n",
    "    print('\\nDone',end='')\n",
    "    return pd.DataFrame({'relation':relations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pheno_data(family_data,\n",
    "    pheno_path,pheno_delimiter,pheno_ID_header,pheno_header,\n",
    "    covar_path,covar_delimiter,covar_ID_header,covar_header):\n",
    "    \n",
    "    # Indicate current task\n",
    "    print('\\nObtaining phenotype info\\n',end='')\n",
    "    \n",
    "    # Read phenotype file\n",
    "    pheno_data = pd.read_csv(pheno_path,sep=pheno_delimiter)[[pheno_ID_header,pheno_header]]\n",
    "    \n",
    "    # Read covariate file\n",
    "    covar_data = pd.read_csv(covar_path,sep=covar_delimiter)[[covar_ID_header,covar_header]]\n",
    "    \n",
    "    # For progress calculation\n",
    "    tic = time.time()\n",
    "    total_length = len(family_data)\n",
    "    \n",
    "    # List phenotype value for each ID in a family\n",
    "    pheno = []\n",
    "    covar = []\n",
    "    missing_ID = 0\n",
    "    missing_value = 0\n",
    "    for index,row in family_data.iterrows():\n",
    "        temp_pheno = []\n",
    "        temp_covar = []\n",
    "        for ID in row[0]:\n",
    "            \n",
    "            # Locate index of phenotype value for ID\n",
    "            ID_index = pheno_data.loc[pheno_data[pheno_ID_header]==ID].index\n",
    "            \n",
    "            # Add value of phenotype onto list\n",
    "            if len(ID_index) == 0:\n",
    "                temp_pheno.append(-9)\n",
    "                temp_covar.append(-9)\n",
    "                missing_ID += 1\n",
    "            elif len(ID_index) == 1:\n",
    "                phenotype = pheno_data.at[pheno_data.loc[pheno_data[pheno_ID_header]==ID].index[0],pheno_header]\n",
    "                covariate = covar_data.at[covar_data.loc[covar_data[covar_ID_header]==ID].index[0],covar_header]\n",
    "                if pd.isna(phenotype):\n",
    "                    phenotype = -9\n",
    "                    missing_value += 1\n",
    "                if pd.isna(covariate):\n",
    "                    covariate = -9\n",
    "                    missing_value += 1\n",
    "                temp_pheno.append(phenotype)\n",
    "                temp_covar.append(covariate)\n",
    "            else:\n",
    "                print('\\nMultiple values found, using first\\n',end='')\n",
    "                phenotype = pheno_data.at[pheno_data.loc[pheno_data[pheno_ID_header]==ID].index[0],pheno_header]\n",
    "                covariate = covar_data.at[covar_data.loc[covar_data[covar_ID_header]==ID].index[0],covar_header]\n",
    "                if pd.isna(phenotype):\n",
    "                    phenotype = -9\n",
    "                    missing_value += 1\n",
    "                if pd.isna(covariate):\n",
    "                    covariate = -9\n",
    "                    missing_value += 1\n",
    "                temp_pheno.append(phenotype)\n",
    "                temp_covar.append(covariate)\n",
    "        \n",
    "        # Rejoin to main list\n",
    "        pheno.append(temp_pheno)\n",
    "        covar.append(temp_covar)\n",
    "        \n",
    "        # Calculate and display progress\n",
    "        toc = time.time()\n",
    "        if toc-tic > 1:\n",
    "            print(f'\\rProgress: {index+1}/{total_length} Missing ID: {missing_ID} Missing Value: {missing_value}',end='')\n",
    "            tic = time.time()\n",
    "    \n",
    "    # Indicate copleted task\n",
    "    print(f'\\rProgress: {index+1}/{total_length} Missing ID: {missing_ID} Missing Value: {missing_value}',end='')\n",
    "    print('\\nDone',end='')\n",
    "    return pd.DataFrame({'phenotype':pheno,'covariate':covar})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_ID(family_data,pheno_data):\n",
    "    \n",
    "    # Indicate current task\n",
    "    print('\\nChoosing individual\\n',end='')\n",
    "\n",
    "    # For progress calculation\n",
    "    tic = time.time()\n",
    "    total_length = len(pheno_data)\n",
    "\n",
    "    # Iterate through dataframe\n",
    "    chosen = []\n",
    "    ignore = []\n",
    "    for index,row in pheno_data.iterrows():\n",
    "        highest_pheno = list(row[0] == max(row[0]))\n",
    "        if sum(highest_pheno) == 1:\n",
    "            target_index = row[0].index(max(row[0]))\n",
    "            chosen.append(family_data.loc[index][0][target_index])\n",
    "            ignore.append(family_data.loc[index][0].pop(target_index))\n",
    "        elif sum(highest_pheno) > 1:\n",
    "            relevant_ID = list(compress(family_data.loc[index][0],highest_pheno))\n",
    "            relevant_covar = list(compress(row[1],highest_pheno))\n",
    "            highest_covar = list(relevant_covar == max(relevant_covar)).index(True)\n",
    "            top_ID = relevant_ID[highest_covar]\n",
    "            for item in family_data.loc[index][0]:\n",
    "                if item == top_ID:\n",
    "                    chosen.append(item)\n",
    "                else:\n",
    "                    ignore.append(item)\n",
    "        else:\n",
    "            display(highest_pheno)\n",
    "            print('Something went REALLY wrong.')\n",
    "        \n",
    "        # Calculate and display progress\n",
    "        toc = time.time()\n",
    "        if toc-tic > 1:\n",
    "            print(f'\\rProgress: {index+1}/{total_length}',end='')\n",
    "            tic = time.time()\n",
    "    \n",
    "    # Indicate completed task\n",
    "    print(f'\\rProgress: {index+1}/{total_length}',end='')\n",
    "    print('\\nDone',end='')\n",
    "    return [pd.DataFrame({'Chosen_IID':chosen}),pd.DataFrame({'Ignore_IID':ignore})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def main():\n",
    "data_path = '../intermediate_files/king_degree_2.kin0.reduced'\n",
    "data_delimiter = ' '\n",
    "ID_header_1 = 'ID1'\n",
    "ID_header_2 = 'ID2'\n",
    "relation_header = 'InfType'\n",
    "pheno_path = '../../regenie/regenie_input/PD_ltfh.txt'\n",
    "pheno_delimiter = ' '\n",
    "pheno_ID_header = 'IID'\n",
    "pheno_header = 'ltfh'\n",
    "covar_path = '../../regenie/regenie_input/PD_covar.txt'\n",
    "covar_delimiter = ' '\n",
    "covar_ID_header = 'IID'\n",
    "covar_header = 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouping IDs in the same family\n",
      "Progress: 39438/39438 Family Count: 31115\n",
      "Done"
     ]
    }
   ],
   "source": [
    "family_data = group_families(data_path,data_delimiter,ID_header_1,ID_header_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Obtaining relationships in family\n",
      "Progress: 31115/31115\n",
      "Done"
     ]
    }
   ],
   "source": [
    "relation_data = obtain_relations(data_path,data_delimiter,ID_header_1,ID_header_2,relation_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Obtaining phenotype info\n",
      "Progress: 31115/31115 Missing ID: 28 Missing Value: 1\n",
      "Done"
     ]
    }
   ],
   "source": [
    "pheno_data = match_pheno_data(family_data,\n",
    "    pheno_path,pheno_delimiter,pheno_ID_header,pheno_header,\n",
    "    covar_path,covar_delimiter,covar_ID_header,covar_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choosing individual\n",
      "Progress: 31115/31115\n",
      "Done"
     ]
    }
   ],
   "source": [
    "ID_data = choose_ID(family_data,pheno_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_data[0].to_csv('../keep_IDs.txt',sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_data[1].to_csv('../remove_IDs.txt',sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
